
###  [9. Prompt Learning to 3D](#content)
  [[Tevet et al. (ARXIV '22)]( https://guytevet.github.io/motionclip-page/static/source/MotionCLIP.pdf )] MotionCLIP: Exposing Human Motion Generation to CLIP Space
  [[Project]( https://guytevet.github.io/motionclip-page/ )]
  [[Code]( https://github.com/GuyTevet/MotionCLIP )]

  [[Wang et al. (**CVPR '22**)]( https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.html )] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields
  [[Project]( https://cassiepython.github.io/clipnerf/ )]
  [[Code]( https://github.com/cassiePython/CLIPNeRF )]
  [[Video]( https://cassiepython.github.io/clipnerf/images/video.mp4 )]

  [[Michel et al. (ARXIV '21)]( https://arxiv.org/abs/2112.03221 )] Text2Mesh: Text-Driven Neural Stylization for Meshes
  [[Project]( https://threedle.github.io/text2mesh/ )]
  [[Code]( https://github.com/threedle/text2mesh )]
